# Ch10 建立屬於自己的大型語言模型
章節難度: ★★★☆☆
## 內容簡介
大型語言模型的參數量非常龐大，因此通常無法只憑一張顯示卡進行訓練，我們需要使用一些量化技術及不同的微調方式來協助訓練。在本章中，我們將介紹一個非常強大的開源模型LLaMA，並用其幫助我們完成模型的訓練。

1. #### LLaMA介紹：在本章中，我將會告訴你LLaMA對原始Transformer所做的改動，而這些改動也是目前大型語言模型的主流架構，因此理解LLaMA 的設計，對於我們掌握大型語言模型的原理非常有幫助。
2. #### QLoRA & NEFtune：大型語言模型的微調通常有許多方式，這裡除了介紹在微調時常用的QLoRA 技術之外，我還會說明NEFtune 這一個作法的使用方法。
3. #### 微調自己的聊天機器人：在文章的最後，我會用LLaMA 3告訴你如何微調一個聊天機器人（Chat 版本），並將先前提及的優化方式加入模型中，使其能夠更好地回應。

## 額外教材推薦
* 無

## 修改紀錄
* 無
